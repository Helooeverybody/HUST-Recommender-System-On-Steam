{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import Reader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from surprise import SVD, SVDpp, NMF\n",
    "from cmfrec import CMF\n",
    "from utility_surprise import run_surprise\n",
    "from utility_cmfrec import run_cmfrec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_csv(\"../../preprocessed_data/ratings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3483739, 4)\n",
      "(870400, 4)\n"
     ]
    }
   ],
   "source": [
    "rec_train, rec_test = train_test_split(ratings,test_size= 0.2, random_state= 42)\n",
    "users_train,games_train = rec_train[\"user_id\"].unique(), rec_train[\"app_id\"].unique()\n",
    "rec_test =rec_test.loc[rec_test[\"user_id\"].isin(users_train) & rec_test[\"app_id\"].isin(games_train)]\n",
    "testset = list(zip(rec_test.user_id.values, rec_test.app_id.values, rec_test.explicit_rating.values))\n",
    "print(rec_train.shape)\n",
    "print(rec_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_rating = rec_train.explicit_rating.min()\n",
    "max_rating = rec_train.explicit_rating.max()\n",
    "reader = Reader(rating_scale=(min_rating, max_rating))\n",
    "data = Dataset.load_from_df(rec_train[['user_id', 'app_id', 'explicit_rating']], reader)\n",
    "trainset = data.build_full_trainset() \n",
    "testset = list(zip(rec_test.user_id.values, rec_test.app_id.values, rec_test.explicit_rating.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Processing epoch 20\n",
      "Processing epoch 21\n",
      "Processing epoch 22\n",
      "Processing epoch 23\n",
      "Processing epoch 24\n",
      "Processing epoch 25\n",
      "Processing epoch 26\n",
      "Processing epoch 27\n",
      "Processing epoch 28\n",
      "Processing epoch 29\n",
      "Processing epoch 30\n",
      "Processing epoch 31\n",
      "Processing epoch 32\n",
      "Processing epoch 33\n",
      "Processing epoch 34\n",
      "Processing epoch 35\n",
      "Processing epoch 36\n",
      "Processing epoch 37\n",
      "Processing epoch 38\n",
      "Processing epoch 39\n",
      "Processing epoch 40\n",
      "Processing epoch 41\n",
      "Processing epoch 42\n",
      "Processing epoch 43\n",
      "Processing epoch 44\n",
      "Processing epoch 45\n",
      "Processing epoch 46\n",
      "Processing epoch 47\n",
      "Processing epoch 48\n",
      "Processing epoch 49\n",
      "Done. time taken : 0:02:08.239798 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:30.618712\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.8472426407470928\n",
      "\n",
      "MAPE : 27.8128015065595\n",
      "\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:07.584804\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 0.9435609287535055\n",
      "\n",
      "MAPE : 31.580015657601212\n",
      "\n",
      "Precision@10 : 0.8010879978731972\n",
      "\n",
      "Recall@10 : 0.6579230299738579\n",
      "\n",
      "F1@10 : 0.693516505739964\n",
      "\n",
      "NDCG@5: 0.8280883458556083\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:02:46.444298\n"
     ]
    }
   ],
   "source": [
    "svd = SVD(random_state = 42, n_factors = 50, n_epochs = 50 ,verbose = True, lr_all= 0.05, reg_all=0.15)\n",
    "train,test= run_surprise(svd, trainset, testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      " processing epoch 0\n",
      " processing epoch 1\n",
      " processing epoch 2\n",
      " processing epoch 3\n",
      " processing epoch 4\n",
      " processing epoch 5\n",
      " processing epoch 6\n",
      " processing epoch 7\n",
      " processing epoch 8\n",
      " processing epoch 9\n",
      " processing epoch 10\n",
      " processing epoch 11\n",
      " processing epoch 12\n",
      " processing epoch 13\n",
      " processing epoch 14\n",
      " processing epoch 15\n",
      " processing epoch 16\n",
      " processing epoch 17\n",
      " processing epoch 18\n",
      " processing epoch 19\n",
      " processing epoch 20\n",
      " processing epoch 21\n",
      " processing epoch 22\n",
      " processing epoch 23\n",
      " processing epoch 24\n",
      " processing epoch 25\n",
      " processing epoch 26\n",
      " processing epoch 27\n",
      " processing epoch 28\n",
      " processing epoch 29\n",
      " processing epoch 30\n",
      " processing epoch 31\n",
      " processing epoch 32\n",
      " processing epoch 33\n",
      " processing epoch 34\n",
      " processing epoch 35\n",
      " processing epoch 36\n",
      " processing epoch 37\n",
      " processing epoch 38\n",
      " processing epoch 39\n",
      " processing epoch 40\n",
      " processing epoch 41\n",
      " processing epoch 42\n",
      " processing epoch 43\n",
      " processing epoch 44\n",
      " processing epoch 45\n",
      " processing epoch 46\n",
      " processing epoch 47\n",
      " processing epoch 48\n",
      " processing epoch 49\n",
      "Done. time taken : 1:09:34.378566 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:07:52.907892\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.8432361696171434\n",
      "\n",
      "MAPE : 27.683274859017715\n",
      "\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:03:04.854041\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 0.94423501371431\n",
      "\n",
      "MAPE : 31.633924808281193\n",
      "\n",
      "Precision@10 : 0.8012917839921673\n",
      "\n",
      "Recall@10 : 0.6583188212567963\n",
      "\n",
      "F1@10 : 0.6939718850165822\n",
      "\n",
      "NDCG@5: 0.8282865812396605\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 1:20:32.140499\n"
     ]
    }
   ],
   "source": [
    "svdpp = SVDpp(random_state = 42, n_factors = 50, n_epochs = 50 ,verbose = True, lr_all= 0.05, reg_all= 0.15)\n",
    "train,test= run_surprise(svdpp,trainset, testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "Processing epoch 20\n",
      "Processing epoch 21\n",
      "Processing epoch 22\n",
      "Processing epoch 23\n",
      "Processing epoch 24\n",
      "Processing epoch 25\n",
      "Processing epoch 26\n",
      "Processing epoch 27\n",
      "Processing epoch 28\n",
      "Processing epoch 29\n",
      "Processing epoch 30\n",
      "Processing epoch 31\n",
      "Processing epoch 32\n",
      "Processing epoch 33\n",
      "Processing epoch 34\n",
      "Processing epoch 35\n",
      "Processing epoch 36\n",
      "Processing epoch 37\n",
      "Processing epoch 38\n",
      "Processing epoch 39\n",
      "Processing epoch 40\n",
      "Processing epoch 41\n",
      "Processing epoch 42\n",
      "Processing epoch 43\n",
      "Processing epoch 44\n",
      "Processing epoch 45\n",
      "Processing epoch 46\n",
      "Processing epoch 47\n",
      "Processing epoch 48\n",
      "Processing epoch 49\n",
      "Done. time taken : 0:03:33.387449 \n",
      "\n",
      "Evaluating the model with train data..\n",
      "time taken : 0:00:38.746613\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE : 0.8652966526265895\n",
      "\n",
      "MAPE : 29.17108228631344\n",
      "\n",
      "\n",
      "adding train results in the dictionary..\n",
      "\n",
      "Evaluating for test data...\n",
      "time taken : 0:00:09.286282\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE : 1.0238124655417766\n",
      "\n",
      "MAPE : 34.91622681684729\n",
      "\n",
      "Precision@10 : 0.7909280301164712\n",
      "\n",
      "Recall@10 : 0.7427614777148779\n",
      "\n",
      "F1@10 : 0.7384157581124109\n",
      "\n",
      "NDCG@5: 0.8206079370865293\n",
      "storing the test results in test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm : 0:04:21.424348\n"
     ]
    }
   ],
   "source": [
    "nmf = NMF(random_state = 42, n_factors = 40, n_epochs = 50 ,verbose = True)\n",
    "train,test= run_surprise(nmf, trainset, testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from math import log2\n",
    "\n",
    "my_seed = 15\n",
    "random.seed(my_seed)\n",
    "np.random.seed(my_seed)\n",
    "\n",
    "def get_ratings(predictions):\n",
    "    actual = np.array([pred.r_ui for pred in predictions])\n",
    "    pred = np.array([pred.est for pred in predictions])\n",
    "    return actual, pred\n",
    "def get_errors(predictions):\n",
    "    actual, pred = get_ratings(predictions)\n",
    "    rmse = np.sqrt(np.mean((pred - actual)**2))\n",
    "    mape = np.mean(np.abs(actual-pred)/actual) * 100\n",
    "    return rmse, mape\n",
    "def evaluation(predictions, k=5, threshold=3.5):\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "    precisions = defaultdict()\n",
    "    recalls = defaultdict()\n",
    "    ndcgs = defaultdict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "        dcg = sum(true_r / log2(i+2) if true_r >= threshold else 0 for i,(_, true_r) in enumerate(user_ratings[:k]))\n",
    "        sorted_true = sorted(user_ratings, key = lambda x: x[1], reverse = True)\n",
    "        idcg = sum(true_r / log2(i+2) if true_r >= threshold else 0 for i,(_, true_r) in enumerate(sorted_true[:k]))\n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "        n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:10])\n",
    "        n_rel_and_rec_k = sum(\n",
    "            ((true_r >= threshold) and (est >= threshold))\n",
    "            for (est, true_r) in user_ratings[:10]\n",
    "        )\n",
    "        ndcgs[uid] = dcg/idcg if idcg!= 0 else 0\n",
    "        precisions[uid]= n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "        recalls[uid]= n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "    precision = sum(prec for prec in precisions.values()) / len(precisions)\n",
    "    recall = sum(rec for rec in recalls.values()) / len(recalls)\n",
    "    ndcg = sum(nd for nd in ndcgs.values()) / len(ndcgs)\n",
    "    f1_score = sum((2*precisions[i]*recalls[i]/(precisions[i]+ recalls[i])) if precisions[i] +recalls[i] != 0 else 0 for i in (precisions.keys()))/len(precisions)\n",
    "\n",
    "    return precision, recall, f1_score , ndcg\n",
    "def run_surprise(algo, trainset, testset, verbose=True): \n",
    "    start = datetime.now()\n",
    "    train = dict()\n",
    "    test = dict()\n",
    "    st = datetime.now()\n",
    "    print('Training the model...')\n",
    "    algo.fit(trainset)\n",
    "    print('Done. time taken : {} \\n'.format(datetime.now()-st))\n",
    "    st = datetime.now()\n",
    "    print('Evaluating the model with train data..')\n",
    "    train_preds = algo.test(trainset.build_testset())\n",
    "    precision, recall,f1, ndcg = evaluation(train_preds)\n",
    "    train_rmse, train_mape = get_errors(train_preds)\n",
    "    print('time taken : {}'.format(datetime.now()-st))\n",
    "    if verbose:\n",
    "        print('-'*15)\n",
    "        print('Train Data')\n",
    "        print('-'*15)\n",
    "        print(\"RMSE : {}\\n\\nMAPE : {}\\n\".format(train_rmse, train_mape))\n",
    "        print()\n",
    "    if verbose:\n",
    "        print('adding train results in the dictionary..')\n",
    "    train['rmse'] = train_rmse\n",
    "    train['mape'] = train_mape\n",
    "    train['recall'] = recall\n",
    "    train['precision'] = precision\n",
    "    train['f1'] = f1\n",
    "    st = datetime.now()\n",
    "    print('\\nEvaluating for test data...')\n",
    "    test_preds = algo.test(testset)\n",
    "    test_rmse, test_mape = get_errors(test_preds)\n",
    "    precision, recall,f1,ndcg = evaluation(test_preds)\n",
    "   \n",
    "    print('time taken : {}'.format(datetime.now()-st))\n",
    "    if verbose:\n",
    "        print('-'*15)\n",
    "        print('Test Data')\n",
    "        print('-'*15)\n",
    "        print(\"RMSE : {}\\n\\nMAPE : {}\\n\".format(test_rmse, test_mape))\n",
    "        print(\"Precision@10 : {}\\n\\nRecall@10 : {}\\n\\nF1@10 : {}\\n\\nNDCG@5: {}\".format(precision, recall, f1, ndcg))\n",
    "    if verbose:\n",
    "        print('storing the test results in test dictionary...')\n",
    "    test['rmse'] = test_rmse\n",
    "    test['mape'] = test_mape\n",
    "    print('\\n'+'-'*45)\n",
    "    print('Total time taken to run this algorithm :', datetime.now() - start)\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Done. Time taken: 0:00:34.764835 \n",
      "\n",
      "Evaluating the model with train data...\n",
      "Time taken: 0:00:22.865107\n",
      "---------------\n",
      "Train Data\n",
      "---------------\n",
      "RMSE: 0.8397834611442527\n",
      "\n",
      "MAE: 28.767264846897323\n",
      "\n",
      "\n",
      "Adding train results to the dictionary...\n",
      "\n",
      "Evaluating the model with test data...\n",
      "Time taken: 0:00:18.009073\n",
      "---------------\n",
      "Test Data\n",
      "---------------\n",
      "RMSE: 0.8397834611442527\n",
      "\n",
      "MAE: 28.767264846897323\n",
      "\n",
      "Precision@10: 0.9503289434957759\n",
      "\n",
      "Recall@10: 0.28261004622987496\n",
      "\n",
      "F1@10: 0.4222205324876224\n",
      "\n",
      "NDCG@5: 0.9511299262006849\n",
      "Storing the test results in the test dictionary...\n",
      "\n",
      "---------------------------------------------\n",
      "Total time taken to run this algorithm: 0:01:15.806487\n"
     ]
    }
   ],
   "source": [
    "als = CMF(k= 50 , method = 'als', lambda_ = 35)\n",
    "train, test = run_cmfrec(als , rec_train, rec_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
