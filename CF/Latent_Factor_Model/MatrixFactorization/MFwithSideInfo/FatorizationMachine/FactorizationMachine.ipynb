{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import copy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_features = pd.read_csv(\"../preprocessed_data/users_features.csv\")\n",
    "games_features = pd.read_csv(\"../preprocessed_data/games_features.csv\")\n",
    "explicit_data = pd.read_csv(\"../preprocessed_data/ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_list = []\n",
    "add_user_index = len(users_features)\n",
    "user_index_by_id = {id : idx for idx, id in enumerate(users_features['user_id'])}\n",
    "for  index,row in users_features.iterrows():\n",
    "    true_indices = row[row == True].index.tolist()\n",
    "    column_indices = [index] + [users_features.columns.get_loc(col) + add_user_index -1 for col in true_indices]\n",
    "    users_list.append(column_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "games_list = []\n",
    "add_game_index = len(games_features)\n",
    "games_index_by_id = {id : (idx) for idx, id in enumerate(games_features['app_id'])}\n",
    "for  index,row in games_features.iterrows():\n",
    "    true_indices = row[row == True].index.tolist()\n",
    "    column_indices = [index + add_user_index + 20] + [games_features.columns.get_loc(col)+add_user_index+add_game_index+20 -1 for col in true_indices]\n",
    "    games_list.append(column_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratings, validation_ratings = train_test_split(explicit_data, test_size= 0.1, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94469"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_inputs = games_list[-1][0] + len(games_features.columns)\n",
    "total_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_MOVIES = len(games_list)\n",
    "NUM_USERS = len(users_list)\n",
    "padding_idx = total_inputs\n",
    "\n",
    "\n",
    "class FactorizationMachineDataset(Dataset):\n",
    "    def __init__(self, rating_df):\n",
    "        self.rating_df = rating_df\n",
    "        self.max_size = 5  \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.rating_df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        user_index = user_index_by_id[self.rating_df[\"user_id\"].iloc[index]]\n",
    "      \n",
    "        games_index = games_index_by_id[self.rating_df[\"app_id\"].iloc[index]]\n",
    "     \n",
    "        rating = self.rating_df[\"rating\"].iloc[index]\n",
    "      \n",
    "        users_feature = users_features.iloc[user_index]\n",
    "    \n",
    "        games_feature = games_features[games_index]\n",
    "      \n",
    "        padding_size = self.max_size - len(users_feature) - len(games_feature)\n",
    "        feature = users_feature + games_feature + [padding_idx] * padding_size\n",
    "        \n",
    "        return torch.IntTensor(feature), rating\n",
    "\n",
    "\n",
    "training_data = FactorizationMachineDataset(train_ratings)\n",
    "validation_data = FactorizationMachineDataset(validation_ratings)\n",
    "\n",
    "batch_size = 128\n",
    "num_workers = 10\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    training_data, batch_size=batch_size, shuffle=True, num_workers=num_workers\n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "    validation_data, batch_size=batch_size, shuffle=False, num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FactorizationMachine(nn.Module):\n",
    "    def __init__(self,num_input, num_factor):\n",
    "        super(FactorizationMachine, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_input + 1, num_factor, padding_idx= padding_idx)\n",
    "        self.embedding.weight.data.uniform_(-1,1)\n",
    "        torch.nn.init.xavier_normal_(self.embedding.weight.data,gain = 1e-3)\n",
    "        self.linear_layer = nn.Embedding(num_input+1, 1, padding_idx= padding_idx)\n",
    "        self.bias = nn.Parameter(data = torch.rand(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)\n",
    "        pow_of_sum = emb.sum(dim = 1 , keepdim = True).pow(2).sum(dim = 2)\n",
    "        sum_of_pow = emb.pow(2).sum(dim = 1 , keepdim = True).sum(dim = 2)\n",
    "        out_inter = 0.5 * (pow_of_sum - sum_of_pow)\n",
    "        out_lin = self.linear_layer(x).sum(dim = 1)\n",
    "        out = out_inter + out_lin + self.bias\n",
    "        return out\n",
    "def rmse(predictions, targets):\n",
    "    return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "def train(model, train_dataloader, validation_dataloader, epochs=10, device='cpu'):\n",
    "    torch.manual_seed(42)\n",
    "    print(\"he\")\n",
    "    model = model.to(device)\n",
    "    print(\"he\")\n",
    "    criterion = nn.MSELoss()\n",
    "    print(\"he\")\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9)\n",
    "    print(\"he\")\n",
    "\n",
    "    best_score = float('inf')\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    print(\"he\")\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        print(\"he\")\n",
    "        train_loss = 0\n",
    "        i =0 \n",
    "        for batch_x, batch_y in train_dataloader:\n",
    "            print(i)\n",
    "            i+=1\n",
    "            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x)\n",
    "            loss = criterion(outputs.squeeze(), batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * batch_x.size(0)\n",
    "        train_loss /= len(train_dataloader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_x, batch_y in validation_dataloader:\n",
    "                batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n",
    "                outputs = model(batch_x)\n",
    "                loss = criterion(outputs.squeeze(), batch_y)\n",
    "                val_loss += loss.item() * batch_x.size(0)\n",
    "        val_loss /= len(validation_dataloader.dataset)\n",
    "\n",
    "        if val_loss < best_score:\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            best_score = val_loss\n",
    "\n",
    "        print(f'Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f} - Valid RMSE: {val_loss:.4f}')\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he\n",
      "he\n",
      "he\n",
      "he\n",
      "he\n",
      "he\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_factors = 80\n",
    "model = FactorizationMachine(num_input=total_inputs, num_factor=n_factors)\n",
    "train(model, train_dataloader, validation_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
