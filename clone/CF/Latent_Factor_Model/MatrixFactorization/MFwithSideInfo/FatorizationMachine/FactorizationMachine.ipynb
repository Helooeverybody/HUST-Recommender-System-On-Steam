{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EbmunztZJhGk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
        "import copy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from model import FactorizationMachine\n",
        "from evaluation import evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Om__jKQBJhGl"
      },
      "outputs": [],
      "source": [
        "users_features = pd.read_csv(\"../../preprocessed_data/users_features.csv\")\n",
        "games_features = pd.read_csv(\"../../preprocessed_data/games_features.csv\")\n",
        "explicit_data = pd.read_csv(\"../../preprocessed_data/ratings.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8AFSIctnJhGm"
      },
      "outputs": [],
      "source": [
        "users_list = []\n",
        "add_user_index = len(users_features)\n",
        "user_index_by_id = {id : idx for idx, id in enumerate(users_features['user_id'])}\n",
        "for  index,row in users_features.iterrows():\n",
        "    true_indices = row[row == True].index.tolist()\n",
        "    column_indices = [index] + [users_features.columns.get_loc(col) + add_user_index -1 for col in true_indices]\n",
        "    users_list.append(column_indices)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "KjerzsKTJhGm"
      },
      "outputs": [],
      "source": [
        "games_list = []\n",
        "add_game_index = len(games_features)\n",
        "games_index_by_id = {id : (idx) for idx, id in enumerate(games_features['app_id'])}\n",
        "for  index,row in games_features.iterrows():\n",
        "    true_indices = row[row == True].index.tolist()\n",
        "    column_indices = [index + add_user_index + 15] + [games_features.columns.get_loc(col)+add_user_index+add_game_index+15 -1 for col in true_indices]\n",
        "    games_list.append(column_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "iJT5-RHwJhGm"
      },
      "outputs": [],
      "source": [
        "train_ratings, validation_ratings = train_test_split(explicit_data, test_size= 0.2, random_state= 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF3DxxyGJhGm",
        "outputId": "884d0627-6286-4c1e-8b68-f3f6d6b1a4cb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "94469"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "total_inputs = games_list[-1][0] + len(games_features.columns)\n",
        "NUM_MOVIES = len(games_list)\n",
        "NUM_USERS = len(users_list)\n",
        "padding_idx = total_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "esnL9bq3JhGn"
      },
      "outputs": [],
      "source": [
        "class FactorizationMachineDataset(Dataset):\n",
        "    def __init__(self, rating_df):\n",
        "        self.rating_df = rating_df\n",
        "        self.max_size = 20\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.rating_df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        users_index = user_index_by_id[self.rating_df[\"user_id\"].iloc[index]]\n",
        "\n",
        "        games_index = games_index_by_id[self.rating_df[\"app_id\"].iloc[index]]\n",
        "        rating = self.rating_df[\"explicit_rating\"].iloc[index]\n",
        "        users_feature = users_list[users_index]\n",
        "\n",
        "        games_feature = games_list[games_index]\n",
        "\n",
        "        padding_size = self.max_size - len(users_feature) - len(games_feature)\n",
        "        feature = users_feature + games_feature + [padding_idx] * padding_size\n",
        "\n",
        "        return torch.IntTensor(feature), rating\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_data = FactorizationMachineDataset(train_ratings)\n",
        "validation_data = FactorizationMachineDataset(validation_ratings)\n",
        "\n",
        "batch_size = 1024\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    training_data, batch_size=batch_size, shuffle=True, num_workers=10\n",
        ")\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "    validation_data, batch_size=batch_size, shuffle=False, num_workers=10\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "BU-7H-EPJhGn"
      },
      "outputs": [],
      "source": [
        "def train(model, train_dataloader, validation_dataloader, epochs=20, k=5, threshold=3.5):\n",
        "    torch.manual_seed(42)\n",
        "    model.train()\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.05, momentum=0.9)\n",
        "\n",
        "    best_score = float('inf')\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_loss = 0\n",
        "\n",
        "        for batch_x, batch_y in train_dataloader:\n",
        "            batch_x = batch_x.to(torch.long)\n",
        "            batch_y = batch_y.to(torch.float)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_x)\n",
        "            loss = criterion(outputs.squeeze(), batch_y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item() * batch_x.size(0)\n",
        "        train_loss /= len(train_dataloader.dataset)\n",
        "\n",
        "        val_loss = 0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        all_user_ids = []\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            for batch_x, batch_y in validation_dataloader:\n",
        "                outputs = model(batch_x)\n",
        "                loss = criterion(outputs.squeeze(), batch_y)\n",
        "                val_loss += loss.item() * batch_x.size(0)\n",
        "                all_preds.append(outputs.squeeze().cpu().numpy())\n",
        "                all_labels.append(batch_y.cpu().numpy())\n",
        "                all_user_ids.append(batch_x[:, 0].cpu().numpy())\n",
        "        val_loss /= len(validation_dataloader.dataset)\n",
        "\n",
        "        all_preds = np.concatenate(all_preds)\n",
        "        all_labels = np.concatenate(all_labels)\n",
        "        all_user_ids = np.concatenate(all_user_ids)\n",
        "\n",
        "        precision, recall, f1_k, ndcg_k = evaluation(all_preds, all_labels,all_user_ids, k, threshold)\n",
        "\n",
        "        if val_loss < best_score:\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            best_score = val_loss\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{epochs} - Train Loss: {train_loss:.4f} - Valid RMSE: {val_loss:.4f} - F1@{10}: {f1_k:.4f} - NDCG@{k}: {ndcg_k:.4f} - Precision@{10}: {precision:.4f} - Recall@{10}: {recall:.4f}')\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlZeX8diJhGn",
        "outputId": "d5394496-6d5b-46b1-f777-77c8bc1498b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15 - Train Loss: 1.9912 - Valid RMSE: 1.2417 - F1@10: 0.6486 - NDCG@5: 0.8060 - Precision@10: 0.7686 - Recall@10: 0.6248\n",
            "Epoch 2/15 - Train Loss: 1.2862 - Valid RMSE: 1.0345 - F1@10: 0.7014 - NDCG@5: 0.8168 - Precision@10: 0.7973 - Recall@10: 0.6759\n",
            "Epoch 3/15 - Train Loss: 1.0946 - Valid RMSE: 1.6192 - F1@10: 0.7495 - NDCG@5: 0.7895 - Precision@10: 0.7784 - Recall@10: 0.7800\n",
            "Epoch 4/15 - Train Loss: 1.0386 - Valid RMSE: 1.0519 - F1@10: 0.5882 - NDCG@5: 0.8196 - Precision@10: 0.7922 - Recall@10: 0.5096\n",
            "Epoch 5/15 - Train Loss: 0.9641 - Valid RMSE: 1.1831 - F1@10: 0.5274 - NDCG@5: 0.8197 - Precision@10: 0.7764 - Recall@10: 0.4390\n",
            "Epoch 6/15 - Train Loss: 0.9250 - Valid RMSE: 1.1323 - F1@10: 0.7460 - NDCG@5: 0.8085 - Precision@10: 0.7924 - Recall@10: 0.7557\n",
            "Epoch 7/15 - Train Loss: 0.9043 - Valid RMSE: 1.0150 - F1@10: 0.5829 - NDCG@5: 0.8217 - Precision@10: 0.7857 - Recall@10: 0.5073\n",
            "Epoch 8/15 - Train Loss: 0.8928 - Valid RMSE: 1.0095 - F1@10: 0.7314 - NDCG@5: 0.8169 - Precision@10: 0.7925 - Recall@10: 0.7281\n",
            "Epoch 9/15 - Train Loss: 0.8839 - Valid RMSE: 0.9313 - F1@10: 0.7146 - NDCG@5: 0.8230 - Precision@10: 0.8035 - Recall@10: 0.6894\n",
            "Epoch 10/15 - Train Loss: 0.8728 - Valid RMSE: 0.9170 - F1@10: 0.6583 - NDCG@5: 0.8281 - Precision@10: 0.8059 - Recall@10: 0.6004\n",
            "Epoch 11/15 - Train Loss: 0.8665 - Valid RMSE: 0.9810 - F1@10: 0.7196 - NDCG@5: 0.8155 - Precision@10: 0.7876 - Recall@10: 0.7113\n",
            "Epoch 12/15 - Train Loss: 0.8591 - Valid RMSE: 0.9272 - F1@10: 0.7064 - NDCG@5: 0.8196 - Precision@10: 0.7987 - Recall@10: 0.6786\n",
            "Epoch 13/15 - Train Loss: 0.8528 - Valid RMSE: 0.9863 - F1@10: 0.6221 - NDCG@5: 0.8233 - Precision@10: 0.8039 - Recall@10: 0.5471\n",
            "Epoch 14/15 - Train Loss: 0.8465 - Valid RMSE: 0.9587 - F1@10: 0.6504 - NDCG@5: 0.8118 - Precision@10: 0.7872 - Recall@10: 0.5983\n",
            "Epoch 15/15 - Train Loss: 0.8422 - Valid RMSE: 0.9437 - F1@10: 0.6309 - NDCG@5: 0.8258 - Precision@10: 0.8024 - Recall@10: 0.5607\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "FactorizationMachine(\n",
              "  (embedding): Embedding(94470, 80, padding_idx=94469)\n",
              "  (linear_layer): Embedding(94470, 1, padding_idx=94469)\n",
              ")"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "n_factors = 80\n",
        "model = FactorizationMachine(num_input=total_inputs, num_factor=n_factors)\n",
        "train(model, train_dataloader, validation_dataloader, epochs = 15)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
